{"format": "layers-model", "generatedBy": "keras v2.10.0", "convertedBy": "TensorFlow.js Converter v3.18.0", "modelTopology": {"keras_version": "2.10.0", "backend": "tensorflow", "model_config": {"class_name": "Functional", "config": {"name": "encoder", "layers": [{"class_name": "InputLayer", "config": {"batch_input_shape": [null, 101], "dtype": "float32", "sparse": false, "ragged": false, "name": "encoder_input"}, "name": "encoder_input", "inbound_nodes": []}, {"class_name": "Embedding", "config": {"name": "encoder_embedding", "trainable": true, "batch_input_shape": [null, null], "dtype": "float32", "input_dim": 30, "output_dim": 256, "embeddings_initializer": {"class_name": "RandomUniform", "config": {"minval": -0.05, "maxval": 0.05, "seed": null}}, "embeddings_regularizer": null, "activity_regularizer": null, "embeddings_constraint": null, "mask_zero": true, "input_length": null}, "name": "encoder_embedding", "inbound_nodes": [[["encoder_input", 0, 0, {}]]]}, {"class_name": "LSTM", "config": {"name": "encoder_lstm", "trainable": true, "dtype": "float32", "return_sequences": false, "return_state": true, "go_backwards": false, "stateful": false, "unroll": false, "time_major": false, "units": 512, "activation": "tanh", "recurrent_activation": "sigmoid", "use_bias": true, "kernel_initializer": {"class_name": "GlorotUniform", "config": {"seed": null}, "shared_object_id": 3}, "recurrent_initializer": {"class_name": "Orthogonal", "config": {"gain": 1.0, "seed": null}, "shared_object_id": 4}, "bias_initializer": {"class_name": "Zeros", "config": {}, "shared_object_id": 5}, "unit_forget_bias": true, "kernel_regularizer": null, "recurrent_regularizer": null, "bias_regularizer": null, "activity_regularizer": null, "kernel_constraint": null, "recurrent_constraint": null, "bias_constraint": null, "dropout": 0.0, "recurrent_dropout": 0.0, "implementation": 2}, "name": "encoder_lstm", "inbound_nodes": [[["encoder_embedding", 0, 0, {}]]]}], "input_layers": [["encoder_input", 0, 0]], "output_layers": [["encoder_lstm", 0, 1], ["encoder_lstm", 0, 2]]}}}, "weightsManifest": [{"paths": ["group1-shard1of2.bin", "group1-shard2of2.bin"], "weights": [{"name": "encoder_embedding/embeddings", "shape": [30, 256], "dtype": "float32"}, {"name": "encoder_lstm/lstm_cell/kernel", "shape": [256, 2048], "dtype": "float32"}, {"name": "encoder_lstm/lstm_cell/recurrent_kernel", "shape": [512, 2048], "dtype": "float32"}, {"name": "encoder_lstm/lstm_cell/bias", "shape": [2048], "dtype": "float32"}]}]}